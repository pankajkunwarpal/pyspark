{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Return the number of distinct words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\n",
    "    \"Counting word occurences from a book.\"\n",
    ").getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6595"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you need to read multiple text files, replace `1342-0` by `*`.\n",
    "results = (\n",
    "    spark.read.text(\"./DataAnalysisPythonPySpark/data/data/gutenberg_books/1342-0.txt\")\n",
    "    .select(F.split(F.col(\"value\"), \" \").alias(\"line\"))\n",
    "    .select(F.explode(F.col(\"line\")).alias(\"word\"))\n",
    "    .select(F.lower(F.col(\"word\")).alias(\"word\"))\n",
    "    .select(F.regexp_extract(F.col(\"word\"), \"[a-z']*\", 0).alias(\"word\"))\n",
    "    .where(F.col(\"word\") != \"\")\n",
    "    # .groupby(F.col(\"word\"))\n",
    "    .distinct()\n",
    "    .count()\n",
    ")\n",
    "results\n",
    "# results.orderBy(\"count\", ascending=False).show(10)\n",
    "# results.coalesce(1).write.csv(\"./results_single_partition.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ```Getting the words that appears only once.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|     word|count|\n",
      "+---------+-----+\n",
      "|   online|    4|\n",
      "|     some|  203|\n",
      "|    still|   72|\n",
      "|      few|   72|\n",
      "|     hope|  122|\n",
      "|    those|   60|\n",
      "| cautious|    4|\n",
      "|   lady's|    8|\n",
      "|imitation|    1|\n",
      "|      art|    3|\n",
      "+---------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "None\n",
      "6595\n"
     ]
    }
   ],
   "source": [
    "# If you need to read multiple text files, replace `1342-0` by `*`.\n",
    "results = (\n",
    "    spark.read.text(\"./DataAnalysisPythonPySpark/data/data/gutenberg_books/1342-0.txt\")\n",
    "    .select(F.split(F.col(\"value\"), \" \").alias(\"line\"))\n",
    "    .select(F.explode(F.col(\"line\")).alias(\"word\"))\n",
    "    .select(F.lower(F.col(\"word\")).alias(\"word\"))\n",
    "    .select(F.regexp_extract(F.col(\"word\"), \"[a-z']*\", 0).alias(\"word\"))\n",
    "    .where(F.col(\"word\") != \"\")\n",
    "    .groupby(F.col(\"word\"))\n",
    "    # .distinct()\n",
    "    .count()\n",
    "    # .where(F.col('count') == 1)\n",
    "    # .orderBy('word', ascending=True)\n",
    ")\n",
    "print(results.show(10))\n",
    "print(results.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|first_letter|sum(count)|\n",
      "+------------+----------+\n",
      "|           t|     16101|\n",
      "|           a|     13684|\n",
      "|           h|     10419|\n",
      "|           w|      9091|\n",
      "|           s|      8791|\n",
      "+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.withColumn('first_letter', F.substring(F.col('word'), 1, 1)).groupby(F.col('first_letter')).sum() \\\n",
    "    .orderBy('Sum(Count)', ascending=False).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+\n",
      "|First_letter_Vowel|sum(count)|\n",
      "+------------------+----------+\n",
      "|              true|     33522|\n",
      "|             false|     88653|\n",
      "+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.withColumn('First_letter_Vowel',\n",
    "F.substring(F.col('word'), 1, 1).isin(['a','e','i','o','u']),) \\\n",
    "    .groupby(F.col(\"First_letter_Vowel\")).sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = spark.read.csv('./DataAnalysisPythonPySpark/data/data/broadcast_logs/BroadcastLogs_2018_Q3_M8_sample.csv', sep='|',\n",
    "header=True, inferSchema=True, timestampFormat='yyyy-MM-dd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.show(5, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = spark.read.csv('./sample.csv',header=True,inferSchema=True,\n",
    "quote='$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Item: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      "\n",
      "None\n",
      "+---------------+--------+-----+\n",
      "|           Item|Quantity|Price|\n",
      "+---------------+--------+-----+\n",
      "|Banana, organic|       1| 0.99|\n",
      "|           Pear|       7| 1.24|\n",
      "|Cake, chocolate|       1| 14.5|\n",
      "+---------------+--------+-----+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(sample.printSchema())\n",
    "print(sample.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+-------------------+\n",
      "|BroadcastLogID|LogServiceID|LogDate            |\n",
      "+--------------+------------+-------------------+\n",
      "|1196192316    |3157        |2018-08-01 00:00:00|\n",
      "|1196192317    |3157        |2018-08-01 00:00:00|\n",
      "|1196192318    |3157        |2018-08-01 00:00:00|\n",
      "|1196192319    |3157        |2018-08-01 00:00:00|\n",
      "|1196192320    |3157        |2018-08-01 00:00:00|\n",
      "+--------------+------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(logs.select('BroadcastLogID', 'LogServiceID', 'LogDate').show(5,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BroadcastLogID',\n",
       " 'LogServiceID',\n",
       " 'LogDate',\n",
       " 'SequenceNO',\n",
       " 'AudienceTargetAgeID',\n",
       " 'AudienceTargetEthnicID',\n",
       " 'CategoryID',\n",
       " 'ClosedCaptionID',\n",
       " 'CountryOfOriginID',\n",
       " 'DubDramaCreditID',\n",
       " 'EthnicProgramID',\n",
       " 'ProductionSourceID',\n",
       " 'ProgramClassID',\n",
       " 'FilmClassificationID',\n",
       " 'ExhibitionID',\n",
       " 'Duration',\n",
       " 'EndTime',\n",
       " 'LogEntryDate',\n",
       " 'ProductionNO',\n",
       " 'ProgramTitle',\n",
       " 'StartTime',\n",
       " 'Subtitle',\n",
       " 'NetworkAffiliationID',\n",
       " 'SpecialAttentionID',\n",
       " 'BroadcastOriginPointID',\n",
       " 'CompositionID',\n",
       " 'Producer1',\n",
       " 'Producer2',\n",
       " 'Language1',\n",
       " 'Language2']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:  ['BroadcastLogID' 'LogServiceID' 'LogDate' 'SequenceNO'\n",
      " 'AudienceTargetAgeID']\n",
      "Columns:  ['AudienceTargetEthnicID' 'CategoryID' 'ClosedCaptionID'\n",
      " 'CountryOfOriginID' 'DubDramaCreditID']\n",
      "Columns:  ['EthnicProgramID' 'ProductionSourceID' 'ProgramClassID'\n",
      " 'FilmClassificationID']\n",
      "Columns:  ['ExhibitionID' 'Duration' 'EndTime' 'LogEntryDate']\n",
      "Columns:  ['ProductionNO' 'ProgramTitle' 'StartTime' 'Subtitle']\n",
      "Columns:  ['NetworkAffiliationID' 'SpecialAttentionID' 'BroadcastOriginPointID'\n",
      " 'CompositionID']\n",
      "Columns:  ['Producer1' 'Producer2' 'Language1' 'Language2']\n"
     ]
    }
   ],
   "source": [
    "col_split = np.array_split(\n",
    "    np.array(logs.columns), len(logs.columns)//4\n",
    ")\n",
    "for i in col_split:\n",
    "    print(\"Columns: \", i, end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+-------------------+----------+-------------------+\n",
      "|BroadcastLogID|LogServiceID|LogDate            |SequenceNO|AudienceTargetAgeID|\n",
      "+--------------+------------+-------------------+----------+-------------------+\n",
      "|1196192316    |3157        |2018-08-01 00:00:00|1         |4                  |\n",
      "|1196192317    |3157        |2018-08-01 00:00:00|2         |null               |\n",
      "|1196192318    |3157        |2018-08-01 00:00:00|3         |null               |\n",
      "|1196192319    |3157        |2018-08-01 00:00:00|4         |null               |\n",
      "|1196192320    |3157        |2018-08-01 00:00:00|5         |null               |\n",
      "+--------------+------------+-------------------+----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------------------+----------+---------------+-----------------+----------------+\n",
      "|AudienceTargetEthnicID|CategoryID|ClosedCaptionID|CountryOfOriginID|DubDramaCreditID|\n",
      "+----------------------+----------+---------------+-----------------+----------------+\n",
      "|null                  |13        |3              |3                |null            |\n",
      "|null                  |null      |1              |null             |null            |\n",
      "|null                  |null      |1              |null             |null            |\n",
      "|null                  |null      |1              |null             |null            |\n",
      "|null                  |null      |1              |null             |null            |\n",
      "+----------------------+----------+---------------+-----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------------+------------------+--------------+--------------------+\n",
      "|EthnicProgramID|ProductionSourceID|ProgramClassID|FilmClassificationID|\n",
      "+---------------+------------------+--------------+--------------------+\n",
      "|null           |10                |19            |null                |\n",
      "|null           |null              |20            |null                |\n",
      "|null           |null              |3             |null                |\n",
      "|null           |null              |3             |null                |\n",
      "|null           |null              |3             |null                |\n",
      "+---------------+------------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------+----------------+----------------+-------------------+\n",
      "|ExhibitionID|Duration        |EndTime         |LogEntryDate       |\n",
      "+------------+----------------+----------------+-------------------+\n",
      "|2           |02:00:00.0000000|08:00:00.0000000|2018-08-01 00:00:00|\n",
      "|null        |00:00:30.0000000|06:13:45.0000000|2018-08-01 00:00:00|\n",
      "|null        |00:00:15.0000000|06:14:00.0000000|2018-08-01 00:00:00|\n",
      "|null        |00:00:15.0000000|06:14:15.0000000|2018-08-01 00:00:00|\n",
      "|null        |00:00:15.0000000|06:14:30.0000000|2018-08-01 00:00:00|\n",
      "+------------+----------------+----------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------+-------------------------------------------+----------------+--------+\n",
      "|ProductionNO|ProgramTitle                               |StartTime       |Subtitle|\n",
      "+------------+-------------------------------------------+----------------+--------+\n",
      "|A39082      |Newlywed and Dead                          |06:00:00.0000000|null    |\n",
      "|null        |15-SPECIALTY CHANNELS-Canadian Generic     |06:13:15.0000000|null    |\n",
      "|null        |3-PROCTER & GAMBLE INC-Anti-Perspirant 3rd |06:13:45.0000000|null    |\n",
      "|null        |12-CREDIT KARMA-Bank/Credit Union/Trust 3rd|06:14:00.0000000|null    |\n",
      "|null        |3-L'OREAL CANADA-Hair Products 3rd         |06:14:15.0000000|null    |\n",
      "+------------+-------------------------------------------+----------------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+------------------+----------------------+-------------+\n",
      "|NetworkAffiliationID|SpecialAttentionID|BroadcastOriginPointID|CompositionID|\n",
      "+--------------------+------------------+----------------------+-------------+\n",
      "|null                |null              |null                  |null         |\n",
      "|null                |null              |null                  |null         |\n",
      "|null                |null              |null                  |null         |\n",
      "|null                |null              |null                  |null         |\n",
      "|null                |null              |null                  |null         |\n",
      "+--------------------+------------------+----------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+---------+---------+---------+\n",
      "|Producer1|Producer2|Language1|Language2|\n",
      "+---------+---------+---------+---------+\n",
      "|null     |null     |94       |null     |\n",
      "|null     |null     |null     |null     |\n",
      "|null     |null     |null     |null     |\n",
      "|null     |null     |null     |null     |\n",
      "|null     |null     |null     |null     |\n",
      "+---------+---------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in  col_split:\n",
    "    logs.select(*x).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[BroadcastLogID: int, LogServiceID: int, LogDate: timestamp, SequenceNO: int, AudienceTargetAgeID: int, AudienceTargetEthnicID: int, CategoryID: int, ClosedCaptionID: int, CountryOfOriginID: int, DubDramaCreditID: int, EthnicProgramID: int, ProductionSourceID: int, ProgramClassID: int, FilmClassificationID: int, ExhibitionID: int, Duration: string, EndTime: string, LogEntryDate: timestamp, ProductionNO: string, ProgramTitle: string, StartTime: string, Subtitle: string, NetworkAffiliationID: int, SpecialAttentionID: int, BroadcastOriginPointID: int, CompositionID: int, Producer1: string, Producer2: string, Language1: int, Language2: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Dropping BroadCastLogID and SequennceNo not usefull columns.\n",
    "logs = logs.drop(*['BroadCastLogID', 'SequenceNo'])\n",
    "\n",
    "# Testing columns presence.\n",
    "print(\"BroadCastLogID\" in logs.columns)\n",
    "print(\"SequenceNo\" in logs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+-------------------+\n",
      "|BroadcastLogID|LogServiceID|LogDate            |\n",
      "+--------------+------------+-------------------+\n",
      "|1196192316    |3157        |2018-08-01 00:00:00|\n",
      "|1196192317    |3157        |2018-08-01 00:00:00|\n",
      "|1196192318    |3157        |2018-08-01 00:00:00|\n",
      "|1196192319    |3157        |2018-08-01 00:00:00|\n",
      "|1196192320    |3157        |2018-08-01 00:00:00|\n",
      "+--------------+------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# here False means show result without truncate\n",
    "logs.select(\"BroadcastLogID\",\"LogServiceID\",\"LogDate\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Duration', 'string')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use of date and time case.\n",
    "\n",
    "logs.select(F.col(\"Duration\")).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+-----------+-----------+\n",
      "|        Duration|dur_hours|dur_minutes|dur_seconds|\n",
      "+----------------+---------+-----------+-----------+\n",
      "|00:04:52.0000000|        0|          4|         52|\n",
      "|00:10:06.0000000|        0|         10|          6|\n",
      "|00:26:41.0000000|        0|         26|         41|\n",
      "|00:09:52.0000000|        0|          9|         52|\n",
      "|00:04:26.0000000|        0|          4|         26|\n",
      "+----------------+---------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use of pyspark substring functionality.\n",
    "logs.select(\n",
    "    F.col(\"Duration\"),\n",
    "    F.col(\"Duration\").substr(1,2).cast(\"int\").alias(\"dur_hours\"),\n",
    "    F.col(\"Duration\").substr(4,2).cast(\"int\").alias(\"dur_minutes\"),\n",
    "    F.col(\"Duration\").substr(7,2).cast(\"int\").alias(\"dur_seconds\"),\n",
    ").distinct().show(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- BroadcastLogID: integer (nullable = true)\n",
      " |-- LogServiceID: integer (nullable = true)\n",
      " |-- LogDate: timestamp (nullable = true)\n",
      " |-- SequenceNO: integer (nullable = true)\n",
      " |-- AudienceTargetAgeID: integer (nullable = true)\n",
      " |-- AudienceTargetEthnicID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- ClosedCaptionID: integer (nullable = true)\n",
      " |-- CountryOfOriginID: integer (nullable = true)\n",
      " |-- DubDramaCreditID: integer (nullable = true)\n",
      " |-- EthnicProgramID: integer (nullable = true)\n",
      " |-- ProductionSourceID: integer (nullable = true)\n",
      " |-- ProgramClassID: integer (nullable = true)\n",
      " |-- FilmClassificationID: integer (nullable = true)\n",
      " |-- ExhibitionID: integer (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- EndTime: string (nullable = true)\n",
      " |-- LogEntryDate: timestamp (nullable = true)\n",
      " |-- ProductionNO: string (nullable = true)\n",
      " |-- ProgramTitle: string (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Subtitle: string (nullable = true)\n",
      " |-- NetworkAffiliationID: integer (nullable = true)\n",
      " |-- SpecialAttentionID: integer (nullable = true)\n",
      " |-- BroadcastOriginPointID: integer (nullable = true)\n",
      " |-- CompositionID: integer (nullable = true)\n",
      " |-- Producer1: string (nullable = true)\n",
      " |-- Producer2: string (nullable = true)\n",
      " |-- Language1: integer (nullable = true)\n",
      " |-- Language2: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# renaming one column\n",
    "logs_rename = logs.withColumnRenamed(\"Duration_seconds\", \"duration_seconds\")\n",
    "logs_rename.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use toDF method to \n",
    "    - this method return the new data frame.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      LogServiceID|\n",
      "+-------+------------------+\n",
      "|  count|            238945|\n",
      "|   mean| 3450.890284375065|\n",
      "| stddev|199.50673962554782|\n",
      "|    min|              3157|\n",
      "|    max|              3925|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|      LogServiceID|\n",
      "+-------+------------------+\n",
      "|  count|            238945|\n",
      "|   mean| 3450.890284375065|\n",
      "| stddev|199.50673962554782|\n",
      "|    min|              3157|\n",
      "|    25%|              3287|\n",
      "|    50%|              3379|\n",
      "|    75%|              3627|\n",
      "|    max|              3925|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use of sorted in select method\n",
    "# logs.select(sorted(logs.columns)).printSchema()\n",
    "\n",
    "# use of description\n",
    "logs.describe(\"LogServiceID\").show()\n",
    "\n",
    "# use of summary method.\n",
    "logs.select(\"LogServiceID\").summary().show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('notenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8bcc056d8b2b2589e91084a5f0304ed47f2b28a6538f385d456b5fb40a355c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
